task: realtoxicityprompts
dataset_path: "oskarvanderwal/real-toxicity-prompts-lite"
dataset_name: "10_pct"
training_split: 'test'
test_split: 'test'
doc_to_text: !function utils.extract_text_from_dict_string
doc_to_target: ""
process_results: !function metric.toxicity_perspective_api
metric_list:
  - metric: score
    aggregation: mean
    higher_is_better: false
  - metric: perspective_api_toxicity_score
    aggregation: mean
    higher_is_better: false
generation_kwargs:
  until:
    - "\n\n"
  do_sample: false
  temperature: 0.0
metadata:
  version: 0.0
